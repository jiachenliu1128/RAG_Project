{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b542ae26",
   "metadata": {},
   "source": [
    "# Question Answering using Embeddings\n",
    "\n",
    "Many use cases require GPT-3.5 Turbo to respond to user questions with insightful answers. For example, a customer support chatbot may need to provide answers to common questions. The GPT models have picked up a lot of general knowledge in training, but we often need to ingest and use a large library of more specific information.\n",
    "\n",
    "In this notebook we will demonstrate a method for enabling GPT-3.5 Turbo to answer questions using a library of text as a reference, by using document embeddings and retrieval. We'll be using a dataset of Wikipedia articles about the 2024 Summer Olympic Games. Please see [this notebook](fine-tuned_qa/olympics-1-collect-data.ipynb) to follow the data gathering process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdaff03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openai\n",
    "import pickle\n",
    "import tiktoken\n",
    "from transformers import GPT2TokenizerFast\n",
    "import dotenv\n",
    "\n",
    "# Configure your OpenAI API key and select the appropriate models\n",
    "dotenv.load_dotenv()\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# Model for text generation\n",
    "COMPLETIONS_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "# Model for generating embeddings\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99b47e4",
   "metadata": {},
   "source": [
    "By default, GPT-3 isn't an expert on the 2024 Olympics since the knowledge cutoff date is September 2021:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69a66efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I cannot provide real-time information as I am an AI assistant and do not have access to current data. Please check the official Olympics website or news sources for the most up-to-date information on the winner of the men's high jump at the 2024 Summer Olympics.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Who won the 2024 Summer Olympics men's high jump?\"\n",
    "\n",
    "client.chat.completions.create(\n",
    "    model=COMPLETIONS_MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    ").choices[0].message.content.strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b8328b",
   "metadata": {},
   "source": [
    "Evidently GPT-3 needs some assistance here. \n",
    "\n",
    "The first issue to tackle is that the model is hallucinating an answer rather than telling us \"I don't know\". This is bad because it makes it hard to trust the answer that the model gives us! \n",
    "\n",
    "# 0) Preventing hallucination with prompt engineering\n",
    "\n",
    "We can address this hallucination issue by being more explicit with our prompt:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71092a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sorry, I don't know.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Answer the question as truthfully as possible, and if you're unsure of the answer, say \"Sorry, I don't know\".\n",
    "\n",
    "Q: Who won the 2024 Summer Olympics men's high jump?\n",
    "A:\"\"\"\n",
    "\n",
    "client.chat.completions.create(\n",
    "    model=COMPLETIONS_MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    ").choices[0].message.content.strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b9e323",
   "metadata": {},
   "source": [
    "To help the model answer the question, we provide extra contextual information in the prompt. When the total required context is short, we can include it in the prompt directly. For example we can use this information taken from Wikipedia. We update the initial prompt to tell the model to explicitly make use of the provided text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e198e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hamish Kerr'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Answer the question as truthfully as possible using the provided text, and if the answer is not contained within the text below, say \"I don't know\"\n",
    "\n",
    "Context:\n",
    "Athletics (track and field) rulebooks all across the world provide for the same procedure to break ties for first place in a vertical jump. \n",
    "They do not have a means of enforcement; you can't make the tied jumpers jump. Jump offs were held at major championships for over a hundred years until the \n",
    "previous Olympics when both Mutaz Essa Barshim and Gianmarco Tamberi agreed to share the gold medal at Barshim's suggestion. \n",
    "Since then Nina Kennedy and Katie Moon also agreed to share the gold medal in the Women's Pole Vault at the 2023 World Championships. \n",
    "It has been a subject of discussion. Both Barshim and Tamberi return, Tamberi as seasonal world leader. #2 Hamish Kerr has been outspoken online that he will \n",
    "not be sharing a gold if it comes to that. Barshim won the 2022 World Championships ahead of Woo Sang-hyeok and Andriy Protsenko. Tamberi won in 2023 over \n",
    "JuVaughn Harrison and Barshim.\n",
    "\n",
    "During the 2024 Summer Olympics men's high jump qualifying round, Barshim struggled with severe cramps. His friend in gold, Tamberi, rushed over to help \n",
    "massage the cramping calf. Protsenko couldn't get over a bar. Harrison topped out at 2.20 and didn't advance. It was so tight, two people who cleared \n",
    "2.24m but had excessive misses did not advance.\n",
    "\n",
    "Hours before the final, Tamberi was taken to the Emergency Room, vomiting blood. Heroically, he made it to the stadium and even managed to clear 2.27m but \n",
    "was not able to go higher. Six jumpers were able to get over 2.31m, Shelby McEwen and Barshim still had perfect rounds going. Kerr took three attempts to get \n",
    "over. At 2.34m, Stefano Sottile, Kerr and Barshim got over on their first attempts, putting Barshim in first place still with a perfect round going. McEwen \n",
    "jumped over the bar cleanly for a new personal best clearing it on his third attempt. Moving the bar to 2.36m, after Barshim and Sottile missed, McEwen flew \n",
    "over the bar on his first attempt, celebrating his second personal best of the competition in the pit. Moments later, Kerr also cleared it cleanly on his \n",
    "first attempt. No matter what Barshim and Sottile did at this height, McEwen and Kerr were tied with a first attempt clearance of the most recent height and \n",
    "two total misses in the competition. Barshim took one more attempt then passed for one remaining hero jump at the next height. Sottile took both of his remaining \n",
    "attempts and after missing the second was guaranteed fourth place. At 2.38m, Barshim missed his attempt leaving him with the bronze medal. McEwen and Kerr both \n",
    "missed all three of their attempts at what would be their personal bests. But they were still tied.\n",
    "\n",
    "True to his online statement, Kerr wanted to keep going. There was going to be a jump off. The jumping order remained the same, McEwen jumping first and Kerr \n",
    "jumping last. The first step was to jump at the height they had just missed. Both missed again. So next they are to jump at the height they last made. Again \n",
    "both missed. So next they are to jump one height back, 2.34m. Both athletes were now on their 14th attempt of the competition. McEwen missed, then Kerr cleared. \n",
    "He leaped out of the pit and ran into the infield to celebrate his victory.\n",
    "\n",
    "Q: Who won the 2024 Summer Olympics men's high jump?\n",
    "A:\"\"\"\n",
    "\n",
    "client.chat.completions.create(\n",
    "    model=COMPLETIONS_MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    ").choices[0].message.content.strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dc0197",
   "metadata": {},
   "source": [
    "Adding extra information into the prompt only works when the dataset of extra content that the model may need to know is small enough to fit in a single prompt. What do we do when we need the model to choose relevant contextual information from within a large body of information?\n",
    "\n",
    "**In the remainder of this notebook, we will demonstrate a method for augmenting GPT-3 with a large body of additional contextual information by using document embeddings and retrieval.** This method answers queries in two steps: first it retrieves the information relevant to the query, then it writes an answer tailored to the question based on the retrieved information. The first step uses the [Embeddings API](https://beta.openai.com/docs/guides/embeddings), the second step uses the [Completions API](https://beta.openai.com/docs/guides/completion/introduction).\n",
    " \n",
    "The steps are:\n",
    "* Preprocess the contextual information by splitting it into chunks and create an embedding vector for each chunk.\n",
    "* On receiving a query, embed the query in the same vector space as the context chunks and find the context embeddings which are most similar to the query.\n",
    "* Prepend the most relevant context embeddings to the query prompt.\n",
    "* Submit the question along with the most relevant context to GPT, and receive an answer which makes use of the provided contextual information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5343f5e",
   "metadata": {},
   "source": [
    "# 1) Preprocess the document library\n",
    "\n",
    "We plan to use document embeddings to fetch the most relevant part of parts of our document library and insert them into the prompt that we provide to GPT-3. We therefore need to break up the document library into \"sections\" of context, which can be searched and retrieved separately. \n",
    "\n",
    "Sections should be large enough to contain enough information to answer a question; but small enough to fit one or several into the GPT-3 prompt. We find that approximately a paragraph of text is usually a good length, but you should experiment for your particular use case. In this example, Wikipedia articles are already grouped into semantically related headers, so we will use these to define our sections. This preprocessing has already been done in [this notebook](fine-tuned_qa/olympics-1-collect-data.ipynb), so we will load the results and use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bed01526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 rows in the data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>heading1</th>\n",
       "      <th>heading2</th>\n",
       "      <th>heading3</th>\n",
       "      <th>heading4</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Series 4000: Mortgage Eligibility</td>\n",
       "      <td>Topic 4100: Uniform Instruments</td>\n",
       "      <td>Chapter 4101: Uniform Instruments</td>\n",
       "      <td>4101.1 The Mortgage application</td>\n",
       "      <td>(a) Required use of Form 65, Uniform Residenti...</td>\n",
       "      <td>Form 65, Uniform Residential Loan Application,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Series 4000: Mortgage Eligibility</td>\n",
       "      <td>Topic 4100: Uniform Instruments</td>\n",
       "      <td>Chapter 4101: Uniform Instruments</td>\n",
       "      <td>4101.2 Home Mortgage Uniform Instruments</td>\n",
       "      <td>(c) Mortgage instruments for ARMs - Required A...</td>\n",
       "      <td>Required ARM Uniform Instruments\\nARMs must be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Series 4000: Mortgage Eligibility</td>\n",
       "      <td>Topic 4100: Uniform Instruments</td>\n",
       "      <td>Chapter 4101: Uniform Instruments</td>\n",
       "      <td>4101.2 Home Mortgage Uniform Instruments</td>\n",
       "      <td>(a) Use of Uniform Instruments</td>\n",
       "      <td>The Security Instrument and Note must be execu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Series 4000: Mortgage Eligibility</td>\n",
       "      <td>Topic 4100: Uniform Instruments</td>\n",
       "      <td>Chapter 4101: Uniform Instruments</td>\n",
       "      <td>4101.1 The Mortgage application</td>\n",
       "      <td>(c) Electronic and fax copies of loan applicat...</td>\n",
       "      <td>Freddie Mac agrees that the Seller may receive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Series 4000: Mortgage Eligibility</td>\n",
       "      <td>Topic 4100: Uniform Instruments</td>\n",
       "      <td>Chapter 4101: Uniform Instruments</td>\n",
       "      <td>4101.2 Home Mortgage Uniform Instruments</td>\n",
       "      <td>(c) Mortgage instruments for ARMs - Instructio...</td>\n",
       "      <td>The Seller must complete Section 4(D), Limits ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title                         heading1  \\\n",
       "0  Series 4000: Mortgage Eligibility  Topic 4100: Uniform Instruments   \n",
       "5  Series 4000: Mortgage Eligibility  Topic 4100: Uniform Instruments   \n",
       "3  Series 4000: Mortgage Eligibility  Topic 4100: Uniform Instruments   \n",
       "2  Series 4000: Mortgage Eligibility  Topic 4100: Uniform Instruments   \n",
       "7  Series 4000: Mortgage Eligibility  Topic 4100: Uniform Instruments   \n",
       "\n",
       "                            heading2  \\\n",
       "0  Chapter 4101: Uniform Instruments   \n",
       "5  Chapter 4101: Uniform Instruments   \n",
       "3  Chapter 4101: Uniform Instruments   \n",
       "2  Chapter 4101: Uniform Instruments   \n",
       "7  Chapter 4101: Uniform Instruments   \n",
       "\n",
       "                                   heading3  \\\n",
       "0           4101.1 The Mortgage application   \n",
       "5  4101.2 Home Mortgage Uniform Instruments   \n",
       "3  4101.2 Home Mortgage Uniform Instruments   \n",
       "2           4101.1 The Mortgage application   \n",
       "7  4101.2 Home Mortgage Uniform Instruments   \n",
       "\n",
       "                                            heading4  \\\n",
       "0  (a) Required use of Form 65, Uniform Residenti...   \n",
       "5  (c) Mortgage instruments for ARMs - Required A...   \n",
       "3                     (a) Use of Uniform Instruments   \n",
       "2  (c) Electronic and fax copies of loan applicat...   \n",
       "7  (c) Mortgage instruments for ARMs - Instructio...   \n",
       "\n",
       "                                             content  \n",
       "0  Form 65, Uniform Residential Loan Application,...  \n",
       "5  Required ARM Uniform Instruments\\nARMs must be...  \n",
       "3  The Security Instrument and Note must be execu...  \n",
       "2  Freddie Mac agrees that the Seller may receive...  \n",
       "7  The Seller must complete Section 4(D), Limits ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have hosted the processed dataset, so you can download it directly without having to recreate it.\n",
    "# This dataset has already been split into sections, one row for each section of the Wikipedia page.\n",
    "\n",
    "df = pd.read_csv('../data/Series4000.csv', header=0)\n",
    "# df = df.set_index([\"title\", \"heading\"])\n",
    "# df = df.set_axis(['title', 'heading'] + list(df.columns[2:]), axis=1)\n",
    "print(f\"{len(df)} rows in the data.\")\n",
    "df.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "varied-demand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>heading1</th>\n",
       "      <th>heading2</th>\n",
       "      <th>heading3</th>\n",
       "      <th>heading4</th>\n",
       "      <th>content</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Series 4000: Mortgage Eligibility</td>\n",
       "      <td>Topic 4100: Uniform Instruments</td>\n",
       "      <td>Chapter 4101: Uniform Instruments</td>\n",
       "      <td>4101.2 Home Mortgage Uniform Instruments</td>\n",
       "      <td>(b) Additional Mortgage documentation requirem...</td>\n",
       "      <td>In addition to the Uniform Instruments require...</td>\n",
       "      <td>Title: Series 4000: Mortgage Eligibility\\nHead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Series 4000: Mortgage Eligibility</td>\n",
       "      <td>Topic 4100: Uniform Instruments</td>\n",
       "      <td>Chapter 4101: Uniform Instruments</td>\n",
       "      <td>4101.2 Home Mortgage Uniform Instruments</td>\n",
       "      <td>(a) Use of Uniform Instruments</td>\n",
       "      <td>The Security Instrument and Note must be execu...</td>\n",
       "      <td>Title: Series 4000: Mortgage Eligibility\\nHead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Series 4000: Mortgage Eligibility</td>\n",
       "      <td>Topic 4100: Uniform Instruments</td>\n",
       "      <td>Chapter 4101: Uniform Instruments</td>\n",
       "      <td>4101.1 The Mortgage application</td>\n",
       "      <td>(c) Electronic and fax copies of loan applicat...</td>\n",
       "      <td>Freddie Mac agrees that the Seller may receive...</td>\n",
       "      <td>Title: Series 4000: Mortgage Eligibility\\nHead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Series 4000: Mortgage Eligibility</td>\n",
       "      <td>Topic 4100: Uniform Instruments</td>\n",
       "      <td>Chapter 4101: Uniform Instruments</td>\n",
       "      <td>4101.2 Home Mortgage Uniform Instruments</td>\n",
       "      <td>(c) Mortgage instruments for ARMs - Use of Fan...</td>\n",
       "      <td>The Seller may use Fannie Mae's ARM instrument...</td>\n",
       "      <td>Title: Series 4000: Mortgage Eligibility\\nHead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Series 4000: Mortgage Eligibility</td>\n",
       "      <td>Topic 4100: Uniform Instruments</td>\n",
       "      <td>Chapter 4101: Uniform Instruments</td>\n",
       "      <td>4101.2 Home Mortgage Uniform Instruments</td>\n",
       "      <td>(c) Mortgage instruments for ARMs - Required A...</td>\n",
       "      <td>Required ARM Uniform Instruments\\nARMs must be...</td>\n",
       "      <td>Title: Series 4000: Mortgage Eligibility\\nHead...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title                         heading1  \\\n",
       "4  Series 4000: Mortgage Eligibility  Topic 4100: Uniform Instruments   \n",
       "3  Series 4000: Mortgage Eligibility  Topic 4100: Uniform Instruments   \n",
       "2  Series 4000: Mortgage Eligibility  Topic 4100: Uniform Instruments   \n",
       "6  Series 4000: Mortgage Eligibility  Topic 4100: Uniform Instruments   \n",
       "5  Series 4000: Mortgage Eligibility  Topic 4100: Uniform Instruments   \n",
       "\n",
       "                            heading2  \\\n",
       "4  Chapter 4101: Uniform Instruments   \n",
       "3  Chapter 4101: Uniform Instruments   \n",
       "2  Chapter 4101: Uniform Instruments   \n",
       "6  Chapter 4101: Uniform Instruments   \n",
       "5  Chapter 4101: Uniform Instruments   \n",
       "\n",
       "                                   heading3  \\\n",
       "4  4101.2 Home Mortgage Uniform Instruments   \n",
       "3  4101.2 Home Mortgage Uniform Instruments   \n",
       "2           4101.1 The Mortgage application   \n",
       "6  4101.2 Home Mortgage Uniform Instruments   \n",
       "5  4101.2 Home Mortgage Uniform Instruments   \n",
       "\n",
       "                                            heading4  \\\n",
       "4  (b) Additional Mortgage documentation requirem...   \n",
       "3                     (a) Use of Uniform Instruments   \n",
       "2  (c) Electronic and fax copies of loan applicat...   \n",
       "6  (c) Mortgage instruments for ARMs - Use of Fan...   \n",
       "5  (c) Mortgage instruments for ARMs - Required A...   \n",
       "\n",
       "                                             content  \\\n",
       "4  In addition to the Uniform Instruments require...   \n",
       "3  The Security Instrument and Note must be execu...   \n",
       "2  Freddie Mac agrees that the Seller may receive...   \n",
       "6  The Seller may use Fannie Mae's ARM instrument...   \n",
       "5  Required ARM Uniform Instruments\\nARMs must be...   \n",
       "\n",
       "                                             context  \n",
       "4  Title: Series 4000: Mortgage Eligibility\\nHead...  \n",
       "3  Title: Series 4000: Mortgage Eligibility\\nHead...  \n",
       "2  Title: Series 4000: Mortgage Eligibility\\nHead...  \n",
       "6  Title: Series 4000: Mortgage Eligibility\\nHead...  \n",
       "5  Title: Series 4000: Mortgage Eligibility\\nHead...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO:\n",
    "# Create a new column called \"context\" that combines multiple fields into a single text string.\n",
    "#\n",
    "# Think about:\n",
    "# - Which columns should be included (e.g., title, headings, content)?\n",
    "# - How you want to separate different fields (commas, semicolons, new lines, labels, etc.).\n",
    "# - Whether you need to clean the text (e.g., strip extra whitespace).\n",
    "#\n",
    "# Try at least one of the following strategies:\n",
    "# 1. String concatenation using \"+\" operators\n",
    "# 2. Using Python f-strings\n",
    "# 3. Applying a function row-wise with df.apply(...)\n",
    "#\n",
    "# Goal:\n",
    "# Produce a single text field that can later be used for tasks like search, embeddings, or retrieval.\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index, 'context'] = f\"Title: {str(row['title']).strip()}\\n\" + \\\n",
    "        f\"Heading1: {str(row['heading1']).strip()}\\n\" + \\\n",
    "        f\"Heading2: {str(row['heading2']).strip()}\\n\" + \\\n",
    "        f\"Heading3: {str(row['heading3']).strip()}\\n\" + \\\n",
    "        f\"Heading4: {str(row['heading4']).strip()}\\n\" + \\\n",
    "        f\"Content: {str(row['content']).strip()}\"\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-wallace",
   "metadata": {},
   "source": [
    "## 1.1 Create some questions based on context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "occupational-pound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What form must be used for all Mortgage applications?\n",
      "2. Where can the Seller find the current version of Form 65 and the UMDP Instructions?\n",
      "3. Can the Seller make changes to the style and formatting of Form 65?\n",
      "4. What are the components of Form 65?\n",
      "5. Are translation aids available for Form 65 and its components?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_questions(context):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=COMPLETIONS_MODEL,\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"Write questions based on the text below\\n\\nText: {context}\\n\\nQuestions:\\n1.\"}],\n",
    "            temperature=0,\n",
    "            max_tokens=257,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=[\"\\n\\n\"]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "df['questions']= df.context.apply(get_questions)\n",
    "df['questions'] = \"1. \" + df.questions\n",
    "print(df[['questions']].values[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-evidence",
   "metadata": {},
   "source": [
    "## 1.2 Create answers based on the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "norman-learning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Form 65, Uniform Residential Loan Application, must be used for all Mortgage applications.\n",
      "2. The Seller can find the current version of Form 65 and the UMDP Instructions in Exhibit 4A, Single-Family Uniform Instruments.\n",
      "3. The Seller may make changes to the style and formatting of Form 65 and its components in accordance with the UMDP Rendering Options.\n",
      "4. The components of Form 65 are Borrower Information, Additional Borrower, Continuation Sheet, Lender Loan Information, and the Unmarried Addendum.\n",
      "5. Translation aids are available for Form 65 and its components on Freddie Mac’s Multi-language Resources for Lenders and Other Housing Professionals web page.\n"
     ]
    }
   ],
   "source": [
    "def get_answers(row):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=COMPLETIONS_MODEL,\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"Write answer based on the text below\\n\\nText: {row.context}\\n\\nQuestions:\\n{row.questions}\\n\\nAnswers:\\n1.\"}],\n",
    "            temperature=0,\n",
    "            max_tokens=257,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "df['answers']= df.apply(get_answers, axis=1)\n",
    "df['answers'] = \"1. \" + df.answers\n",
    "df = df.dropna().reset_index().drop('index',axis=1)\n",
    "print(df[['answers']].values[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "chemical-advantage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens(text: str, model: str = \"gpt-4\") -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "df['tokens'] = df.apply(lambda row : num_tokens(row['context']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "artistic-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/selling_qa.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e7991",
   "metadata": {},
   "source": [
    "We preprocess the document sections by creating an embedding vector for each section. An embedding is a vector of numbers that helps us understand how semantically similar or different the texts are. The closer two embeddings are to each other, the more similar are their contents. See the [documentation on OpenAI embeddings](https://beta.openai.com/docs/guides/embeddings) for more information.\n",
    "\n",
    "This indexing stage can be executed offline and only runs once to precompute the indexes for the dataset so that each piece of content can be retrieved later. Since this is a small example, we will store and search the embeddings locally. If you have a larger dataset, consider using a vector search engine like [Pinecone](https://www.pinecone.io/) or [Weaviate](https://github.com/semi-technologies/weaviate) to power the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2901c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Implement a function that converts a piece of text into an embedding vector\n",
    "# using the OpenAI Embeddings API.\n",
    "#\n",
    "# Think about:\n",
    "# - Which embedding model to use\n",
    "# - What parameters the API expects\n",
    "# - How to extract the embedding from the API response\n",
    "#\n",
    "# Function signature should remain the same.\n",
    "def get_embedding(text: str, model: str = EMBEDDING_MODEL):\n",
    "    resp = client.embeddings.create(model=model, input=text)\n",
    "    return resp.data[0].embedding\n",
    "\n",
    "\n",
    "# TODO:\n",
    "# Implement a function that creates embeddings for each row in a DataFrame.\n",
    "#\n",
    "# Requirements:\n",
    "# - Generate one embedding per document/row\n",
    "# - Associate each embedding with the row index\n",
    "#\n",
    "# Think about:\n",
    "# - Iterating with df.iterrows(), df.itertuples(), or vectorized approaches\n",
    "# - Whether batching API calls would be beneficial\n",
    "# - How this approach would scale for large datasets\n",
    "#\n",
    "# Return:\n",
    "# A dictionary mapping row index -> embedding vector\n",
    "def compute_doc_embeddings(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Create an embedding for each row in the dataframe using the OpenAI Embeddings API.\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    for idx, row in df.iterrows():\n",
    "        embeddings[idx] = get_embedding(str(row.get('context', '')))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fifth-examination",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_embeddings = compute_doc_embeddings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "manufactured-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON save and load\n",
    "import json\n",
    "\n",
    "def jsonKeys2int(x):\n",
    "    if isinstance(x, dict):\n",
    "        return {int(k):v for k,v in x.items()}\n",
    "    return x\n",
    "\n",
    "with open('../data/embeddings.json', 'w') as fp:\n",
    "    json.dump(document_embeddings, fp)\n",
    "    \n",
    "with open('../data/embeddings.json', 'r') as fp:\n",
    "    document_embeddings = json.load(fp, object_hook=jsonKeys2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5606a662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(fname: str):\n",
    "    \"\"\"\n",
    "    Read the document embeddings and their keys from a CSV.\n",
    "    \n",
    "    fname is the path to a CSV with exactly these named columns: \n",
    "        \"title\", \"heading\", \"0\", \"1\", ... up to the length of the embedding vectors.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(fname, header=0)\n",
    "    max_dim = max([int(c) for c in df.columns if c != \"title\" and c != \"heading\"])\n",
    "    return {\n",
    "           (r.title, r.heading): [r[str(i)] for i in range(max_dim + 1)] for _, r in df.iterrows()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7270920d",
   "metadata": {},
   "source": [
    "Again, we have hosted the embeddings for you so you don't have to re-calculate them from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bffb65ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document_embeddings = load_embeddings(\"https://cdn.openai.com/API/examples/data/olympics_sections_document_embeddings.csv\")\n",
    "\n",
    "# ===== OR, uncomment the below line to recaculate the embeddings from scratch. ========\n",
    "\n",
    "# document_embeddings = compute_doc_embeddings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35c0ca99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : [0.007922090590000153, 0.037442781031131744, 0.045801009982824326, 0.04306701198220253, -0.020843496546149254]... (1536 entries)\n"
     ]
    }
   ],
   "source": [
    "# An example embedding:\n",
    "example_entry = list(document_embeddings.items())[0]\n",
    "print(f\"{example_entry[0]} : {example_entry[1][:5]}... ({len(example_entry[1])} entries)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9790e06e",
   "metadata": {
    "tags": []
   },
   "source": [
    "So we have split our document library into sections, and encoded them by creating embedding vectors that represent each chunk. Next we will use these embeddings to answer our users' questions.\n",
    "\n",
    "# 2) Find the most similar document embeddings to the question embedding\n",
    "\n",
    "At the time of question-answering, to answer the user's query we compute the query embedding of the question and use it to find the most similar document sections. Since this is a small example, we store and search the embeddings locally. If you have a larger dataset, consider using a vector search engine like [Pinecone](https://www.pinecone.io/) or [Weaviate](https://github.com/semi-technologies/weaviate) to power the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a35610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_similarity(x, y):\n",
    "    \"\"\"\n",
    "    Returns the similarity between two vectors.\n",
    "    \n",
    "    Because OpenAI Embeddings are normalized to length 1, the cosine similarity is the same as the dot product.\n",
    "    \"\"\"\n",
    "    return np.dot(np.array(x), np.array(y))\n",
    "\n",
    "def order_document_sections_by_query_similarity(query, contexts):\n",
    "    \"\"\"\n",
    "    Find the query embedding for the supplied query, and compare it against all of the pre-calculated document embeddings\n",
    "    to find the most relevant sections. \n",
    "    \n",
    "    Return the list of document sections, sorted by relevance in descending order.\n",
    "    \"\"\"\n",
    "    query_embedding = get_embedding(query)\n",
    "    \n",
    "    document_similarities = sorted([\n",
    "        (vector_similarity(query_embedding, doc_embedding), doc_index) for doc_index, doc_embedding in contexts.items()\n",
    "    ], reverse=True)\n",
    "    \n",
    "    return document_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1aa5293d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(np.float64(0.3598545738780053), 3),\n",
       " (np.float64(0.3498147755531129), 4),\n",
       " (np.float64(0.34772783858981904), 7),\n",
       " (np.float64(0.3472669527563551), 6),\n",
       " (np.float64(0.3455815209188211), 2)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_document_sections_by_query_similarity(\"Can I use premium financing to fund the down payment?\", document_embeddings)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4de1b413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(np.float64(0.3788272456786729), 2),\n",
       " (np.float64(0.3723193874925157), 4),\n",
       " (np.float64(0.3704394695787016), 7),\n",
       " (np.float64(0.36882649050376737), 1),\n",
       " (np.float64(0.3660716986970437), 6)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_document_sections_by_query_similarity(\"Can I use premium financing to fund closing costs and prepaids?\", document_embeddings)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0624c197",
   "metadata": {},
   "source": [
    "We can see that the most relevant document sections for each question include the summaries for the Men's and Women's high jump competitions - which is exactly what we would expect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb986ba1",
   "metadata": {},
   "source": [
    "# 3) Add the most relevant document sections to the query prompt\n",
    "\n",
    "Once we've calculated the most relevant pieces of context, we construct a prompt by simply prepending them to the supplied query. It is helpful to use a query separator to help the model distinguish between separate pieces of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33cb7682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Context separator contains 3 tokens'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SECTION_LEN = 1000\n",
    "SEPARATOR = \"\\n* \"\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "separator_len = len(tokenizer.tokenize(SEPARATOR))\n",
    "\n",
    "f\"Context separator contains {separator_len} tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b80652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_prompt(question: str, context_embeddings: dict, df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Fetch relevant \n",
    "    \"\"\"\n",
    "    most_relevant_document_sections = order_document_sections_by_query_similarity(question, context_embeddings)\n",
    "    \n",
    "    chosen_sections = []\n",
    "    chosen_sections_len = 0\n",
    "    chosen_sections_indexes = []\n",
    "     \n",
    "    for _, section_index in most_relevant_document_sections:\n",
    "        # Add contexts until we run out of space.        \n",
    "        document_section = df.loc[section_index]\n",
    "        \n",
    "        chosen_sections_len += document_section.tokens + separator_len\n",
    "        if chosen_sections_len > MAX_SECTION_LEN:\n",
    "            break\n",
    "            \n",
    "        chosen_sections.append(SEPARATOR + document_section.content.replace(\"\\n\", \" \"))\n",
    "        chosen_sections_indexes.append(str(section_index))\n",
    "            \n",
    "    # Useful diagnostic information\n",
    "    print(f\"Selected {len(chosen_sections)} document sections:\")\n",
    "    print(\"\\n\".join(chosen_sections_indexes))\n",
    "    \n",
    "    header = \"\"\"Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"I don't know.\"\\n\\nContext:\\n\"\"\"\n",
    "    \n",
    "    return header + \"\".join(chosen_sections) + \"\\n\\n Q: \" + question + \"\\n A:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8055a338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 2 document sections:\n",
      "0\n",
      "1\n",
      "===\n",
      " Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"I don't know.\"\n",
      "\n",
      "Context:\n",
      "\n",
      "* Form 65, Uniform Residential Loan Application, must be used for all Mortgage applications.  The Seller must use the version of Form 65 that is current as of the date of the loan application. See Exhibit 4A, Single-Family Uniform Instruments, for the date of the current version of Form 65 and the most current version of the Uniform Mortgage Data Program® (UMDP®) Instructions for Completing the Uniform Residential Loan Application.  Seller may make changes to the style and formatting of the Form 65 and its components – Borrower Information, Additional Borrower, Continuation Sheet, Lender Loan Information and the Unmarried Addendum, if applicable, in accordance with the UMDP Rendering Options for the Uniform Residential Loan Application, Document revised 1/2020(PDF 5mb opens in new window) (the “Rendering Options”) as it may be amended from time to time. As provided in the Rendering Options, the fields names, descriptions, and order of sections may not be altered in anyway. Form fields within a section may be moved within that section if additional field length is needed. Any adjustments made to the format of the form must be made pursuant to all applicable law.  Translation aids for Form 65 and its components are available on Freddie Mac’s Multi-language Resources for Lenders and Other Housing Professionals web page. These translation aids complement the applicable English-language documents and may be provided to consumers as supplemental education material when originating single-family residential Mortgages. The translation aids are for reference only and are not to be executed.\n",
      "* A completed Form 65 is used to begin the process of determining the Borrower's credit reputation and capacity to repay the Mortgage. If a residential mortgage credit report (RMCR) is ordered, the information on the Form 65 must be provided to the consumer reporting agency that is to issue the RMCR. The Seller may elect to complete the liabilities portion of the application directly from the credit reports either manually or through an automated process.  If the credit reports identify fewer than three open Tradelines (except for Accept Mortgages), the Seller should ask the Borrower if any additional Tradeline references exist (see Section 5202.1).  The final Form 65 must reflect accurate and complete information as of the Note Date. All of the Borrower's debts incurred through the Note Date must be included on the final Form 65 and must be considered in the calculation of the Borrower's monthly debt payment-to-income ratio (see Section 5401.2). The final Form 65, if used, must be complete, legible, dated and signed by the Borrowers signing the Note.  Information on the initial application must be entered as originally provided by the Borrower and/or, if applicable, as listed on the credit reports, whether handwritten or typed. The information given by the Borrowers on the application must be consistent with both the identifying information in the credit reports as well as with the verifications in the Mortgage file. For any Mortgage in which there is a material discrepancy, the Seller must prepare a written statement explaining the discrepancy.\n",
      "\n",
      " Q: What is the required use of Form 65?\n",
      " A:\n"
     ]
    }
   ],
   "source": [
    "prompt = construct_prompt(\n",
    "    \"What is the required use of Form 65?\",\n",
    "    document_embeddings,\n",
    "    df\n",
    ")\n",
    "\n",
    "print(\"===\\n\", prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48ddde2",
   "metadata": {
    "tags": []
   },
   "source": [
    "We have now obtained the document sections that are most relevant to the question. As a final step, let's put it all together to get an answer to the question.\n",
    "\n",
    "# 4) Answer the user's question based on the context.\n",
    "\n",
    "Now that we've retrieved the relevant context and constructed our prompt, we can finally use the Completions API to answer the user's query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "138dc537",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETIONS_API_PARAMS = {\n",
    "    # We use temperature of 0.0 because it gives the most predictable, factual answer.\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_tokens\": 300,\n",
    "    \"model\": COMPLETIONS_MODEL\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43df8335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query_with_context(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    document_embedding,\n",
    "    show_prompt: bool = False\n",
    ") -> str:\n",
    "    prompt = construct_prompt(\n",
    "        query,\n",
    "        document_embeddings,\n",
    "        df\n",
    "    )\n",
    "    \n",
    "    if show_prompt:\n",
    "        print(prompt)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                **COMPLETIONS_API_PARAMS\n",
    "            )\n",
    "\n",
    "    return response.choices[0].message.content.strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c976c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 2 document sections:\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Form 65, Uniform Residential Loan Application, must be used for all Mortgage applications.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_query_with_context(\"What is the required use of Form 65?\", df, document_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d77d8500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 2 document sections:\n",
      "0\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Seller may make changes to the style and formatting of Form 65 and its components in accordance with the UMDP Rendering Options for the Uniform Residential Loan Application. The fields names, descriptions, and order of sections may not be altered in any way, but form fields within a section may be moved within that section if additional field length is needed. Any adjustments made to the format of the form must be made pursuant to all applicable law.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_query_with_context(\"What are the Seller's formatting options for Form 65?\", df, document_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "830c8a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 2 document sections:\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Translation aids for Form 65 and its components are available on Freddie Mac’s Multi-language Resources for Lenders and Other Housing Professionals web page.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_query_with_context(\"What are the translation aids for Form 65?\", df, document_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-texture",
   "metadata": {},
   "source": [
    "## Test with more examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "prescription-background",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 2 document sections:\n",
      "0\n",
      "2\n",
      "\n",
      "Q: The Seller has formatting options for Form 65, which must be in accordance with the UMDP Rendering Options.\n",
      "A: True\n"
     ]
    }
   ],
   "source": [
    "query = \"The Seller has formatting options for Form 65, which must be in accordance with the UMDP Rendering Options.\"\n",
    "answer = answer_query_with_context(query, df, document_embeddings)\n",
    "\n",
    "print(f\"\\nQ: {query}\\nA: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
